**Ãndice**

- [**O problema**](#o-problema)
- [**A soluÃ§Ã£o**](#a-soluÃ§Ã£o)
- [E agora, como migrar os dados para nova estrutura?](#e-agora-como-migrar-os-dados-para-nova-estrutura)
- [Sobre a aplicaÃ§Ã£o para ETL](#sobre-a-aplicaÃ§Ã£o-para-etl)
- [Resultado do ETL](#resultado-do-etl)

--------

Opa, espero que estejam bem!

Bom... vou compartilhar uma histÃ³ria de alguns meses mas tentarei ser o mais breve possÃ­vel.

### **O problema**

Em um dos sistemas do cliente da empresa que trabalho, existia um chat de atendimento legado onde era centralizado toda comunicaÃ§Ã£o entre a equipe de atendimento que fazem parte de filiais da empresa do grupo e usuÃ¡rios do sistema, e por ser um sistema legado sempre havia issues de bugs que surgiam por uma falta de boa estrutura de dados, consequentemente tambÃ©m vÃ¡rias issues de performance e escalabilidade levando em consideraÃ§Ã£o que apenas tabelas diretas da funcionalidade que registravam `conversas` e `mensagens` e outras que compunham a consulta destas duas tinham juntas por volta de ~7.5MM de registros, indiretas de `usuÃ¡rios` e `atendentes` envolvidos e outras por volta de mais ~1MM, naquela estrutura e com as consultas necessÃ¡rias esses nÃºmeros jÃ¡ era um problema.

Dito isso, passei alguns meses atendendo issues que para correÃ§Ã£o ou implementaÃ§Ã£o de algo simples era necessÃ¡rio refatorar queries, procedures, manejo de indices, fazer malabarismo de colunas e dados para atender melhor os relacionamentos e consultas (nÃ£o usam ORM, era tudo na unha).

E a discussÃ£o de uma refatoraÃ§Ã£o de toda a funcionalidade sempre estava presente na equipe por causa da forma que estava posto a estrutura de dados, sÃ³ que isso nÃ£o era uma discussÃ£o tÃ£o simples pois existia duas equipes a interna do cliente e a externa que eu faÃ§o parte.

### **A soluÃ§Ã£o**

EntÃ£o alguns meses na luta, a recomendaÃ§Ã£o da refatoraÃ§Ã£o foi atendida pelo cliente, para alegria de todos que esbarravam na funcionalidade e principalmente a minha que estava pegando a maioria das issues.

Como eu jÃ¡ estava familiarizado com parte da estrutura da funcionalidade, fiquei responsÃ¡vel pela refatoraÃ§Ã£o.

NÃ£o vou me aprofundar muito do que foi feito pois nÃ£o Ã© o objetivo a refatoraÃ§Ã£o em si.

ApÃ³s 2 meses de trabalho para entender toda estrutura da funcionalidade, dezenas de procedures visitadas (maioria das regras de negÃ³cio dos sistemas do cliente sÃ£o em procedures), refatorando e atendendo outras issues de outras partes do sistema, finalizei a modelagem das tabelas, os endpoints da funcionalidade, com uma nova estrutura de dados, eliminando tabelas e colunas desnecessÃ¡rias, separando responsabilidades, camada de repositÃ³rio para lidar com o banco, procedures criadas, validaÃ§Ãµes de payload para manter consistÃªncia, tudo documentado para nÃ£o ter desculpa para nÃ£o seguir a padronizaÃ§Ã£o, coisas que na visÃ£o de boa parte Ã© o mÃ­nimo mas atÃ© entÃ£o nÃ£o tinha (isso Ã© muito comum).

Testado endpoints, dupliquei a funcionalidade nos fronts (interface do atendente / interface web do usuÃ¡rio / interface mobile seria feita depois por outro membro do time) apliquei os requisitos de melhoria, criada interface de serviÃ§o, implementa, tudo testado e aprovado no ambiente de desenvolvimento. Ufa.... done!

### E agora, como migrar os dados para nova estrutura?

*Disclaimer: Lembrando que nÃ£o sou DBA ou especialista em banco de dados.*

Chegou o grande momento, migrar os dados, e esse momento levantava um questionamento, qual a melhor forma de fazer isso? E um ponto importante, em menor tempo possÃ­vel, pois a data de entrega se aproximava, para a equipe de QA do cliente comeÃ§arem os testes no ambiente de staging.

Cheguei a avaliar a utilizaÃ§Ã£o de ferramentas prontas no mercado para isso, algumas me pareciam complexas demais para o caso em especÃ­fico, e a principal que aparece para esse cenÃ¡rio Ã© a SSIS da prÃ³pria Microsoft visto que o banco Ã© MSSQL.

Mas o banco estava na AWS e precisaria configura-lo no servidor RDS e naquele momento nÃ£o gostaria de envolver a equipe de infra, e pela minha falta de experiÃªncia com a ferramenta talvez demorasse mais do que fazer por conta prÃ³pria pro caso especÃ­fico, pelas transformaÃ§Ãµes necessÃ¡rias dos dados.

Um exemplo de muitos motivos que me fez pensar assim: a coluna que contia o conteÃºdo da mensagem, tinha 3 tipos de dados diferentes, e um deles era JSON Prosemirror, e todos os tipos deveriam ser convertidos para HTML ou text plain. E existia vÃ¡rias outras ponderaÃ§Ãµes dessas.

### Sobre a aplicaÃ§Ã£o para ETL

Decidi entÃ£o seguir para o desenvolvimento de uma ferramenta simples de ETL, jÃ¡ imaginando um conceito de sistema distribuÃ­do para ganharmos em velocidade processamento usando vÃ¡rios nÃºcleos para processar a fila de registros.

> **Por que usar nÃºcleos ao invÃ©s de threads neste caso?**
>
> Neste caso especÃ­fico, a escolha de utilizar nÃºcleos em vez de threads foi feita visando evitar problemas de concorrÃªncia e assegurar um ambiente isolado para o processamento de cada lote de dados. Com o uso de threads, os recursos do nÃºcleo seriam compartilhados, o que poderia resultar em conflitos entre os diferentes lotes de processamento. Ao optar por nÃºcleos, cada lote Ã© executado em um ambiente separado, com seus prÃ³prios recursos dedicados, como registradores, caches e unidades de execuÃ§Ã£o. Isso proporciona uma divisÃ£o fÃ­sica dos recursos, minimizando a interferÃªncia entre os lotes e impedindo que o desempenho de um lote afete negativamente os outros. AlÃ©m disso, levando em consideraÃ§Ã£o esses fatores, utilizar threads exigiria um gerenciamento mais complexo, e demandaria um tempo que eu nÃ£o tinha disponÃ­vel.

AplicaÃ§Ã£o foi feita em Node, pensada para funcionar num conceito modular, onde poderÃ¡ futuramente ser utilizada como lib tambÃ©m, pois todo o core de gerenciamento Ã© separado das definiÃ§Ãµes do ETL que ficam em `modules` Ã© onde fica toda definiÃ§Ã£o das tabelas de origem e destino, o mapeamento das colunas de origem e destino, e a funÃ§Ã£o de transformaÃ§Ã£o dos dados, dentro de cada modulo. No banco usado para o ETL, serÃ¡ criado uma tabela chamada `etl_queue` onde estarÃ¡ os registros da fila do processamento.

Na funÃ§Ã£o `transformData` Ã© possÃ­vel fazer consultas adicionais, no caso desta funcionalidade de chat de atendimento na tabela que registrava as conversas, foi necessÃ¡rio fazer 8 consultas adicionais no banco para o carregamento das informaÃ§Ãµes na tabela nova de conversas.

NÃ£o vou me aprofundar sobre a aplicaÃ§Ã£o do ETL, pois vocÃªs mesmos podem saber mais e/ou contribuir no repositÃ³rio. :)

> [Github - Database-ETL](https://github.com/martinshumberto/database-etl)

*Essa versÃ£o foi feita pensando em solucionar esse objetivo descrito, dentro de um prazo apertado.*

Estrutura:

```bash
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .eslintrc.js
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .prettierrc
â”œâ”€â”€ .vscode
â”‚   â””â”€â”€ settings.json
â”œâ”€â”€ README.md
â”œâ”€â”€ index.js
â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ etl_combined.log
â”‚   â”œâ”€â”€ etl_error.log
â”‚   â”œâ”€â”€ etl_info.log
â”‚   â”œâ”€â”€ etl_sql.log
â”‚   â””â”€â”€ etl_warn.log
â”œâ”€â”€ package.json
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ config
â”‚   â”‚   â”œâ”€â”€ db.js
â”‚   â”‚   â”œâ”€â”€ etl.js
â”‚   â”‚   â””â”€â”€ log.js
â”‚   â”œâ”€â”€ lib
â”‚   â”‚   â”œâ”€â”€ commands
â”‚   â”‚   â”‚   â”œâ”€â”€ create-module.js
â”‚   â”‚   â”‚   â”œâ”€â”€ reset-state.js
â”‚   â”‚   â”‚   â””â”€â”€ templates
â”‚   â”‚   â”‚       â””â”€â”€ module-index.js
â”‚   â”‚   â”œâ”€â”€ db.js
â”‚   â”‚   â”œâ”€â”€ etl.js
â”‚   â”‚   â”œâ”€â”€ helpers
â”‚   â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”‚   â””â”€â”€ sql.js
â”‚   â”‚   â”œâ”€â”€ log.js
â”‚   â”‚   â”œâ”€â”€ queue.js
â”‚   â””â”€â”€ modules
â”‚       â””â”€â”€ .gitkeep
â””â”€â”€ yarn.lock
```

Tentei deixar o mais reutilizÃ¡vel possÃ­vel sem impactar na entrega no trabalho, mas certamente tem muito o que melhorar. E gostaria muito que vocÃªs contribuÃ­ssem apontando essas melhorias e dando opiniÃ£o se possÃ­vel.

E certamente darei continuidade a ela dentro do possÃ­vel, abrangendo mais banco de dados, e promovendo melhorias jÃ¡ previstas ou que me indiquem, para ter uma ferramenta pronta, versÃ¡til e rÃ¡pida de ETL.

### Resultado do ETL

Abaixo Ã© um recorte da estimativa e defesa enviada para a gerencia do projeto para solicitaÃ§Ã£o de uma maquina para o processamento do ETL com um nÃºmero considerÃ¡vel de nÃºcleos para cumprirmos o prazo.

> ...
>
> **Mensagens:**
> Total de registros: 1.5MM
> Finalizar montagem da fila: Ëœ10min `*`
> Segundos de processamento por 100 registros: 45 seg. (0.45 por registro)
> Total de segundos para processamento: 683.622s
>
> *Estimativas:*
> 1 nÃºcleo = 683.622 segs. = ~7 dias `**`
> 20 nÃºcleos = 683.622/20 segs. = ~9 horas `**`
> 68 nÃºcleos = lotes de 5000 = 239.267/68 segs. = ~1 hora `**`
>
> --------
> `*` A montagem da fila Ã© feita pelo cluster master (0) e de acordo com o valor setado no batchSize (default: 100) vai distribuindo os lotes de forma igualitÃ¡ria para os outros clusters irem processando a fila, e apÃ³s finalizar o lanÃ§amento dos lotes para processamento o cluster master Ã© liberado para processar a fila tambÃ©m.
> `**` Estimativa feita na minha maquina, e ao rodar no AWS serÃ¡ mais rÃ¡pido em torno de ~30/40% por estar na mesma rede interna e na mesma regiÃ£o que o database, a estimativa da AWS jÃ¡ estÃ¡ completando a porcentagem.
>
> ...

E o resultado final foi de: **~1h30m** para todos os mÃ³dulos!

A estimativa total enviada junto ao recorte acima foi de 3hrs.

A maquina utilizada na AWS:
`x2gd.16xlarge com 64 nÃºcleos por $5.344 a hora`

--------

*Importante ressaltar que aqui Ã© uma simplificaÃ§Ã£o de todo o processo para ser o mais breve possÃ­vel e compartilhar com vocÃªs. Sempre hÃ¡ muitas discussÃµes, testes, tentativas, erros, acertos e melhorias a serem feitas.*

--------

Obrigado.

Deixe seu comentÃ¡rio! ğŸ˜„
